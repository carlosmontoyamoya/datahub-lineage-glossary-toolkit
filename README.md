# üß† DataHub Toolkit: Lineage y Glosario Autom√°tico


[![Espa√±ol](https://img.shields.io/badge/Espa√±ol--yellow)](README.md)
[![English](https://img.shields.io/badge/English--blue)](README-en.md)

Este repositorio contiene herramientas para automatizar:

- üîÅ La creaci√≥n de linaje de columnas entre tablas (OpenLineage + DataHub)
- üìö La creaci√≥n de t√©rminos de glosario y su asociaci√≥n autom√°tica a columnas

---


## üìö Tabla de Contenido

- [DataHub Lineage Local Runner](#datahub-lineage-local-runner)
- [DataHub Glossary Local Runner - Asociaciones a Columnas](#datahub-glossary-local-runner---asociaciones-a-columnas)



# DataHub Lineage Local Runner

Este repositorio permite **emitir linaje de columnas entre tablas** de forma local usando [`openlineage-python`](https://github.com/OpenLineage/OpenLineage) y DataHub, integrando un archivo CSV con las relaciones.

---

![Descripci√≥n de la imagen](./img/lineage_01.png)


## üìå Objetivo

Crear eventos de linaje entre datasets de origen y destino definidos en un archivo CSV, y enviarlos al backend de DataHub (GMS) expuesto p√∫blicamente.

---

## üìÅ Estructura del proyecto
```bash
‚îú‚îÄ‚îÄ create_lineage_local.py # Script principal que emite linaje
‚îú‚îÄ‚îÄ config.json # Configuraci√≥n de conexi√≥n con DataHub
‚îú‚îÄ‚îÄ datos.csv # Archivo CSV con las columnas de linaje
‚îú‚îÄ‚îÄ README.md # Documentaci√≥n
```
### üìù Nota Adicional

El repositorio incluye archivos de ejemplo que sirven como plantilla para configurar tu entorno de trabajo sin comprometer informaci√≥n sensible.

datos_example.csv define el formato esperado para el archivo `datos.csv`, el cual ha sido excluido del control de versiones mediante `.gitignore`. Puedes utilizar este archivo de ejemplo como base para crear tu propio `datos.csv`, asegur√°ndote de respetar las columnas y estructura establecidas.

De igual manera,`config_example.json` act√∫a como referencia para construir tu archivo `config.json`, tambi√©n ignorado por Git. A partir de este archivo puedes generar tu propia configuraci√≥n personalizada, manteniendo las claves y estructura necesarias.

---

## üìã Requisitos

- Python >= 3.9 (recomendado usar Anaconda)
- Cuenta en DataHub con GMS expuesto
- Token de autenticaci√≥n (API Key de DataHub)

---

## üì¶ Instalaci√≥n

### 1. Crear y activar ambiente virtual (con Anaconda)

```bash
conda create -n lineage-env python=3.10 -y
conda activate lineage-env
```


### 2. Instalar dependencias
```bash
pip install openlineage-python pandas
```


Tambien se puede instalar usando directamente conda create:
```bash
conda install --file conda-lineage-requirements.txt
```

### 3. Configuraci√≥n
Edita el archivo config.json con:

api_url: URL p√∫blica de tu instancia de DataHub (sin /api/gms)

api_endpoint: normalmente openapi/openlineage/

access_token: tu API Token de DataHub

linage_csv_s3_paths: lista de archivos CSV con definiciones de linaje

```bash
{
  "api_url": "http://<tu-url-datahub>",
  "api_endpoint": "openapi/openlineage/",
  "access_token": "<tu_token>",
  "linage_csv_s3_paths": [
    {
      "name": "lineage-local-test",
      "path": "datos.csv"
    }
  ]
}
```
### 4. Estructura del CSV (datos.csv)
| Campo                      | Tipo | Descripci√≥n                                       |
| -------------------------- | ---- | ------------------------------------------------- |
| job_name                   | str  | Nombre del job que genera el linaje para la relaci√≥n |
| id                         | int  | ID secuencial                                     |
| input\_table\_source       | str  | Fuente (namespace), por ejemplo: `athena`, `glue` |
| input\_table               | str  | Nombre completo tabla de entrada                  |
| input\_column              | str  | Columna origen                                    |
| input\_column\_data\_type  | str  | Tipo de dato                                      |
| input\_add\_schema         | bool | `True` si se desea incluir esquema del input      |
| output\_table\_destination | str  | Destino (namespace)                               |
| output\_table              | str  | Nombre completo tabla destino                     |
| output\_column             | str  | Columna destino                                   |
| output\_column\_data\_type | str  | Tipo de dato                                      |
| output\_add\_schema        | bool | `True` si se desea incluir esquema del output     |
| transformation             | bool | `True` si hay transformaci√≥n en la columna        |

### 5. Ejecuci√≥n
Una vez configurado el entorno, ejecuta:

```bash
python create_lineage_local.py
```
Si todo est√° bien, ver√°s:
```bash
‚úÖ Lineage emitted for job lineage-local-test
```
Luego podr√°s visualizar el linaje en tu consola de DataHub:
Browse ‚Üí Lineage ‚Üí dtpm_gsit_staging_dev.abt_transaccion

### 6. Ejemplo de entrada (datos.csv)
```
job_name,id,input_table_source,input_table,input_column,input_column_data_type,input_add_schema,output_table_destination,output_table,output_column,output_column_data_type,output_add_schema,transformation
sitio,1,athena,dtpm_gsit_raw_dev.sitio,idsitio,string,False,athena,dtpm_gsit_staging_dev.sitio,id_sitio,bigint,False,False
```

---


# DataHub Glossary Local Runner - Asociaciones a Columnas

Este m√≥dulo permite crear t√©rminos de glosario y asociarlos autom√°ticamente a columnas espec√≠ficas de un dataset en DataHub, utilizando editableSchemaMetadata.

---

![Descripci√≥n de la imagen](./img/glossary_01.png)

## üìå Objetivo

Crear t√©rminos de glosario, asignarles owners, y asociarlos correctamente a columnas espec√≠ficas de tablas, de modo que aparezcan como Matched column term en la UI de DataHub.

---

## üìÅ Estructura del proyecto
```bash
‚îú‚îÄ‚îÄ create_glossary_for_column.py   # Script principal para crear t√©rminos y asociarlos a columnas
‚îú‚îÄ‚îÄ glossary_terms.json             # JSON con la definici√≥n de cada t√©rmino, tabla, campo y metadata
‚îú‚îÄ‚îÄ config.json                     # Configuraci√≥n de conexi√≥n al servidor GMS de DataHub
‚îú‚îÄ‚îÄ README_glossary.md              # Este archivo de documentaci√≥n

```

---

## üìã Requisitos

- Python >= 3.9 (recomendado usar Anaconda)
- Cuenta en DataHub con GMS expuesto
- Token de autenticaci√≥n (API Key de DataHub)

---

## üì¶ Instalaci√≥n

### 1. Crear y activar ambiente virtual (con Anaconda)

```bash
conda create -n glossary-env python=3.10 -y
conda activate glossary-env
```


### 2. Instalar dependencias
```bash
pip install acryl-datahub pandas
```


O usando Conda directamente:
```bash
conda install --file conda-glossary-requirements.txt
```

### 3. Configuraci√≥n
config.json

Este archivo contiene la configuraci√≥n de tu instancia de DataHub:

```bash
{
  "api_url": "http://<tu-url-datahub>",
  "access_token": "<tu_token>"
}
```
‚ö†Ô∏è Importante: El campo api_url no debe incluir /api/gms.


### 4. üìù Estructura del archivo glossary_terms.json

```bash
[
  {
    "term": "fecha_trx_abt_transaccion",
    "description": "Fecha y hora en que se registr√≥ la transacci√≥n.",
    "field": "fecha_trx",
    "database": "dtpm_gsit_raw_dev",
    "table": "abt_transaccion",
    "platform": "athena",
    "env": "PROD"
  },
  {
    "term": "direccion_abt_transaccion",
    "description": "Ubicaci√≥n registrada del comprador al momento de la transacci√≥n.",
    "field": "direccion",
    "database": "dtpm_gsit_raw_dev",
    "table": "abt_transaccion",
    "platform": "athena",
    "env": "PROD"
  }
]
```
‚úÖ Consejo: Aseg√∫rate de que el campo "term" tenga relaci√≥n con el nombre de la columna ("field") , es decir si tienes una columna llamada descripci√≥n, pueden existir varia columnas llamadas asi en multiples tablas, por lo tanto seria tener term: direccion_abt_transaccion (nombre de la tabla)_(nombre de la columna) si deseas que se vea como Matches column term en la UI de DataHub, y evitar conflictos de nombres.

### 5. Ejecuci√≥n
Una vez configurado el entorno, ejecuta:

```bash
python create_glossary_for_column.py
```
Deber√≠as ver algo como:
```bash
‚úÖ T√©rmino creado o actualizado: fecha_trx
üë§ Owner asignado al t√©rmino: fecha_trx
üß© Asociado 'fecha_trx' a la columna fecha_trx mediante editableSchemaMetadata
```

### 6. Resultado esperado
El t√©rmino aparecer√° en el m√≥dulo de Glossary en DataHub.

El t√©rmino se mostrar√° en el dataset bajo la columna asociada.

En la vista del t√©rmino ‚Üí Related Entities, ver√°s el dataset y la columna con el badge Matches column term.

üß† Consideraciones importantes

El campo editableSchemaMetadata se aplica a nivel de dataset, por lo tanto todas las asociaciones se agrupan por tabla.

Si ejecutas el script varias veces, los t√©rminos no se duplicar√°n (usa UPSERT).

Puedes complementar con asociaci√≥n a datasetField para mayor control si necesitas mezclar metadata manual con program√°tica.

## Links de Inter√©s

A continuaci√≥n, se presentan algunos enlaces √∫tiles y de referencia relacionados con DataHub:

- [Tutoriales sobre t√©rminos en la API de DataHub](https://docs.datahub.com/docs/api/tutorials/terms/)
- [Documentaci√≥n de las APIs de DataHub](https://docs.datahub.com/docs/api/datahub-apis)